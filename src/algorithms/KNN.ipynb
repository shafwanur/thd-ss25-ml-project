{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc10c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Better Hyperparameter Tuning of KNN. Cross Validation, no testing on testing data -> supposed to be unseen data, can't choose K based on that. #\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline # will be utilized to handle scaling of data AFTER it has been split into train/test by cross-validation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures # Will be used for feature lifting\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e49e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         duration          pps           bps  max_flowiat  mean_flowiat  \\\n",
      "4239   14998574.0   100.076181  1.110846e+04      22930.0  9.999049e+03   \n",
      "10336  14999635.0   113.069418  1.493263e+04      22236.0  8.849342e+03   \n",
      "13527    328509.0    88.277642  2.585013e+04     149429.0  1.173246e+04   \n",
      "16097  10114393.0     2.669463  7.841301e+02    9880750.0  3.890151e+05   \n",
      "875     8365529.0     0.478153  8.080780e+01    8291714.0  2.788510e+06   \n",
      "...           ...          ...           ...          ...           ...   \n",
      "2153      12934.0   154.631205  7.113035e+03      12934.0  1.293400e+04   \n",
      "1046       2624.0  3810.975610  4.641768e+05       1101.0  2.915556e+02   \n",
      "550      212291.0  4361.937152  4.083866e+06      26612.0  2.295038e+02   \n",
      "11057  14443003.0     2.215606  3.101848e+02     922087.0  4.659033e+05   \n",
      "1672   14786319.0     1.758382  1.152417e+02    6754893.0  5.914528e+05   \n",
      "\n",
      "       has_active  has_std_active  has_fiat  has_biat  has_min_flowiat  \\\n",
      "4239            0               0         1         1                1   \n",
      "10336           0               0         1         1                1   \n",
      "13527           0               0         1         1                1   \n",
      "16097           1               0         1         1                1   \n",
      "875             1               0         1         1                1   \n",
      "...           ...             ...       ...       ...              ...   \n",
      "2153            0               0         0         0                1   \n",
      "1046            0               0         1         1                1   \n",
      "550             0               0         1         1                1   \n",
      "11057           0               0         1         1                1   \n",
      "1672            1               1         1         1                1   \n",
      "\n",
      "       has_std_flowiat  has_mean_fiat  has_mean_biat  \n",
      "4239                 1              1              1  \n",
      "10336                1              1              1  \n",
      "13527                1              1              1  \n",
      "16097                1              1              1  \n",
      "875                  1              0              0  \n",
      "...                ...            ...            ...  \n",
      "2153                 0              0              0  \n",
      "1046                 1              1              1  \n",
      "550                  1              1              1  \n",
      "11057                1              1              1  \n",
      "1672                 1              1              1  \n",
      "\n",
      "[14580 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load flagged dataset #\n",
    "dataset_flagged = pd.read_csv(\"flagged.csv\")\n",
    "X = dataset_flagged.drop(['cls', 'Unnamed: 0'], axis=1)\n",
    "Y = dataset_flagged['cls']\n",
    "\n",
    "# Define column types\n",
    "numerical_cols = ['duration', 'pps', 'bps', 'max_flowiat', 'mean_flowiat']\n",
    "binary_cols = [col for col in X.columns if col not in numerical_cols]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=1, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b3534",
   "metadata": {},
   "source": [
    "Looking above, we notice that we have big numbers. It'd be easier to run calculations with smaller values. We will use the StandardScaler to normalize everything before training any of the models.\n",
    "\n",
    "We will first do:\n",
    " - Feature Lifting for the 5 Numerical Values We Have\n",
    " - Feature Selection\n",
    " - Hyperparameter Tuning (Maybe)\n",
    "\n",
    "\n",
    "KNN requires that we tune only the number of neighbors. We will fit multiple values for the neighbor parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59f2d7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min Value</th>\n",
       "      <th>Max Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>601404954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pps</th>\n",
       "      <td>0.019762</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bps</th>\n",
       "      <td>3.557943</td>\n",
       "      <td>617000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_flowiat</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>600109654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_flowiat</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>60700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_active</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_std_active</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_fiat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_biat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_min_flowiat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_std_flowiat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_mean_fiat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_mean_biat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Min Value    Max Value\n",
       "duration          2.000000  601404954.0\n",
       "pps               0.019762    1000000.0\n",
       "bps               3.557943  617000000.0\n",
       "max_flowiat       2.000000  600109654.0\n",
       "mean_flowiat      2.000000   60700000.0\n",
       "has_active        0.000000          1.0\n",
       "has_std_active    0.000000          1.0\n",
       "has_fiat          0.000000          1.0\n",
       "has_biat          0.000000          1.0\n",
       "has_min_flowiat   0.000000          1.0\n",
       "has_std_flowiat   0.000000          1.0\n",
       "has_mean_fiat     0.000000          1.0\n",
       "has_mean_biat     0.000000          1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_flagged = X.agg(['min', 'max']).T # agg applies both the min and max function, T transposes it\n",
    "summary_flagged.columns = ['Min Value', 'Max Value'] # rename columns\n",
    "\n",
    "display(summary_flagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff753d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature count: 13\n",
      "Final feature count after lifting: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14580, 28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Lifting #\n",
    "polynomial_features = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False) # Doesn't include bias columns, will create both interactions and polynomial features\n",
    "lifted_numerical_train = polynomial_features.fit_transform(X_train[numerical_cols])\n",
    "lifted_numerical_test = polynomial_features.transform(X_test[numerical_cols]) \n",
    "\n",
    "poly_feature_names = polynomial_features.get_feature_names_out(numerical_cols)\n",
    "X_train_lifted = pd.DataFrame(lifted_numerical_train, columns=poly_feature_names, index=X_train.index)\n",
    "X_train_lifted = pd.concat([X_train_lifted, X_train[binary_cols]], axis=1) # Combine with binary features\n",
    "\n",
    "# Get new feature names #\n",
    "poly_feature_names = polynomial_features.get_feature_names_out(numerical_cols)\n",
    "\n",
    "# Convert the new arrays back to DataFrames #\n",
    "X_train_lifted = pd.DataFrame(lifted_numerical_train, columns=poly_feature_names, index=X_train.index)\n",
    "X_test_lifted = pd.DataFrame(lifted_numerical_test, columns=poly_feature_names, index=X_test.index)\n",
    "\n",
    "# Combine the new numerical features with the original binary features #\n",
    "X_train_final = pd.concat([X_train_lifted, X_train[binary_cols]], axis=1)\n",
    "X_test_final = pd.concat([X_test_lifted, X_test[binary_cols]], axis=1)\n",
    "\n",
    "print(f\"Original feature count: {X_train.shape[1]}\")\n",
    "print(f\"Final feature count after lifting: {X_train_final.shape[1]}\")\n",
    "display(X_train_final.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "X_test_scaled = scaler.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bb1304",
   "metadata": {},
   "source": [
    "After feature lifting, we will end up with 15 additional columns to select features from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c16c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature names:\n",
      "['bps', 'max_flowiat', 'mean_flowiat', 'duration^2', 'duration pps', 'duration mean_flowiat', 'pps^2', 'pps max_flowiat', 'pps mean_flowiat', 'bps max_flowiat', 'bps mean_flowiat', 'has_std_active', 'has_fiat', 'has_mean_biat']\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection #\n",
    "neighbor = 5\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "selector = SequentialFeatureSelector(knn, n_features_to_select='auto', scoring='accuracy')\n",
    "selector.fit(X_train_scaled, Y_train)\n",
    "\n",
    "selected_features_mask = selector.get_support() # Returns True and False for each feature. \n",
    "selected_feature_names = X_train_final.columns[selected_features_mask]\n",
    "print(\"Selected feature names:\")\n",
    "print(list(selected_feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: KNN with the original and feature selected dataset. Display Results. #\n",
    "\n",
    "knn_original = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_changes = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Run 10-fold cross-validation\n",
    "score_original = cross_val_score(knn_original, X_train, Y_train, cv=10, n_jobs=-1).mean()\n",
    "score_changes = cross_val_score(knn_changes)\n",
    "\n",
    "# Store the result\n",
    "scores_flagged['KNN_Original'] = score_original\n",
    "\n",
    "print(f\"Original Dataset CV Score: {score_original:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
